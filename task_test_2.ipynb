{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only - expires 2022-10-03\n",
      "Using license file c:\\gurobi\\gurobi.lic\n",
      "Read LP format model from file C:\\Users\\Sigve\\AppData\\Local\\Temp\\tmprygh75nc.lp\n",
      "Reading time = 0.07 seconds\n",
      ": 5482 rows, 15138 columns, 66608 nonzeros\n",
      "Read LP format model from file C:\\Users\\Sigve\\AppData\\Local\\Temp\\tmp8mstm15f.lp\n",
      "Reading time = 0.07 seconds\n",
      ": 5482 rows, 15138 columns, 66608 nonzeros\n",
      "Read LP format model from file C:\\Users\\Sigve\\AppData\\Local\\Temp\\tmpki502gue.lp\n",
      "Reading time = 0.06 seconds\n",
      ": 5482 rows, 15138 columns, 66608 nonzeros\n",
      "Model load and preparation time: 73.868981 seconds\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "import cobra.flux_analysis\n",
    "from cobra import Metabolite, Reaction, Model\n",
    "import time\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from src.mp_functions import combinations_subset, parallelize_dataframe, knockout_FBA, knockout_FBA_w_tasks\n",
    "\n",
    "from functools import partial\n",
    "from src.met_task_functions import constrain_model, read_tasks\n",
    "\n",
    "\n",
    "\"\"\"A mess of a document with different code cells.\n",
    "Good to to use for any testing that involves the Recon3D model as it takes some time to load in.\"\"\"\n",
    "\n",
    "start_time = time.time()\n",
    "model_file_path = 'C:/Users/Sigve/Genome_Data/Human1/Human1_GEM/GTEx/brain.xml'\n",
    "model = cobra.io.read_sbml_model(model_file_path)\n",
    "\n",
    "model_list = constrain_model(model, ALLMETSIN=True)\n",
    "#Removes unused model.\n",
    "model_list[2] = None\n",
    "end_time = time.time()\n",
    "print('Model load and preparation time: %.6f seconds' % (end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def tasks_test(task_list: list, model_list: list, gene_ids: list) -> list:\n",
    "    \"\"\"Performs knockout FBA and checks tasks for the knockout. Returns a list of the results; objective value for\n",
    "    general FBA and pass/fail for the tasks.\"\"\"\n",
    "    with model_list[0]:\n",
    "        for gene_id in gene_ids:\n",
    "            try:\n",
    "                model_list[0].genes.get_by_id(gene_id).knock_out()\n",
    "            except KeyError:\n",
    "                return gene_id + ' not in model.'\n",
    "        res = [model_list[0].slim_optimize()]\n",
    "\n",
    "    for task in task_list:\n",
    "        t_model = model_list[task[3]]\n",
    "\n",
    "        with t_model:\n",
    "            for subset in [task[0], task[1]]:\n",
    "                for rx in subset:\n",
    "                    if rx == 'ALLMETSIN':\n",
    "                        # Adds boundary metabolites for other reactions when ALLMETSIN is used\n",
    "                        for r in subset[1:]:\n",
    "                            for m2 in r.metabolites:\n",
    "                                for r2 in m2.reactions:\n",
    "                                    if r2.boundary and r2.id != r.id:\n",
    "                                        r2.add_metabolites({Metabolite(\n",
    "                                                            m2.id[:-4] + 'x[x]',\n",
    "                                                            formula=m2.formula,\n",
    "                                                            name=' '.join(m2.name.split(' ')[:-1]) + ' [Boundary]',\n",
    "                                                            compartment='x'): 1})\n",
    "                        continue\n",
    "                    t_model.add_reaction(rx)\n",
    "\n",
    "            if task[2] != 'nan':\n",
    "                t_model.add_reaction(task[2])\n",
    "\n",
    "            for gene_id in gene_ids:\n",
    "                t_model.genes.get_by_id(gene_id).knock_out()\n",
    "\n",
    "            if t_model.slim_optimize(error_value='nan') == 'nan':\n",
    "                res += [0]\n",
    "            else:\n",
    "                res += [1]\n",
    "\n",
    "\n",
    "    return res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Read and format task data\n",
    "task_list = read_tasks('C:/Users/Sigve/Genome_Data/Human1/Human1_GEM/tasks/essential_tasks.tsv', model_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   phewas_code                            gene_ids   solution  \\\n",
      "0       290.11  [ENSG00000100030, ENSG00000197375] -80.729783   \n",
      "1       290.11  [ENSG00000101577, ENSG00000197375] -80.729783   \n",
      "2       290.11  [ENSG00000102780, ENSG00000197375] -80.729783   \n",
      "3       290.11  [ENSG00000107798, ENSG00000197375] -80.729783   \n",
      "4       290.11  [ENSG00000113448, ENSG00000197375] -80.729783   \n",
      "\n",
      "                                           pass/fail  \n",
      "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
      "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
      "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
      "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
      "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n"
     ]
    }
   ],
   "source": [
    "# Read test data\n",
    "test_data = pd.read_csv('C:/Users/Sigve/Genome_Data/results/model_tests/test_data.csv')\n",
    "test_data['pass/fail'] = test_data.values[:, 4:].tolist()\n",
    "test_data = test_data[['phewas_code', 'gene_ids', 'solution', 'pass/fail']]\n",
    "test_data['gene_ids'] = test_data['gene_ids'].apply(lambda x: x.split(','))\n",
    "print(test_data.head())\n",
    "\n",
    "# Reduce number of entries\n",
    "#test_data = test_data.iloc[:10, :]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n",
      "*** KeyboardInterrupt exception caught in code being profiled."
     ]
    }
   ],
   "source": [
    "g = ['ENSG00000100030', 'ENSG00000197375']\n",
    "%load_ext line_profiler\n",
    "%lprun -f tasks_test tasks_test(task_list, model_list, g)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2451\n",
      "            gene_ids\n",
      "0  [ENSG00000000419]\n",
      "1  [ENSG00000000938]\n",
      "2  [ENSG00000001036]\n",
      "3  [ENSG00000001084]\n",
      "4  [ENSG00000001630]\n"
     ]
    }
   ],
   "source": [
    "gene_list = [[[g.id]] for g in model.genes]\n",
    "print(len(gene_list))\n",
    "gene_list = pd.DataFrame(gene_list, columns=['gene_ids'])\n",
    "print(gene_list.head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FBA runtime: 5325.673097 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "#test_data['results'] = test_data['gene_ids'].apply(partial(tasks_test, task_list, model_list))\n",
    "test_results= parallelize_dataframe(gene_list, partial(combinations_subset, partial(knockout_FBA_w_tasks, task_list, model_list)), 16)\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "print('FBA runtime: %.6f seconds' % (end_time - start_time))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "copy = test_results.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "test_results['solution'] = test_results['results'].apply(lambda x: x[0])\n",
    "test_results['results'] = test_results['results'].apply(lambda x: x[1:])\n",
    "test_results['tasks_results'] = test_results['results']\n",
    "test_results = test_results[['gene_ids', 'solution', 'tasks_results']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "test_results.to_csv('C:/Users/Sigve/Genome_Data/results/model_tests/brain_single_del.tsv', sep='\\t')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n"
     ]
    }
   ],
   "source": [
    "print(len(test_results['tasks_results'].iloc[0]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            gene_ids   solution  \\\n",
      "0  [ENSG00000000419]  87.693483   \n",
      "1  [ENSG00000000938]  87.693483   \n",
      "2  [ENSG00000001036]  87.693483   \n",
      "3  [ENSG00000001084]  87.693483   \n",
      "4  [ENSG00000001630]   0.000000   \n",
      "\n",
      "                                       tasks_results  \n",
      "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
      "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
      "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
      "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
      "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'results'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32m~\\miniconda3\\envs\\Master\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001B[0m in \u001B[0;36mget_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3360\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3361\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcasted_key\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3362\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\envs\\Master\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\envs\\Master\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'results'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_13712/3667480369.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtest_results\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhead\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[1;32mfor\u001B[0m \u001B[0md\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mtest_results\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'results'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhead\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0md\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\envs\\Master\\lib\\site-packages\\pandas\\core\\frame.py\u001B[0m in \u001B[0;36m__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3453\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnlevels\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3454\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_getitem_multilevel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3455\u001B[1;33m             \u001B[0mindexer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3456\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mis_integer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mindexer\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3457\u001B[0m                 \u001B[0mindexer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mindexer\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\envs\\Master\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001B[0m in \u001B[0;36mget_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3361\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcasted_key\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3362\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3363\u001B[1;33m                 \u001B[1;32mraise\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3364\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3365\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mis_scalar\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0misna\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mand\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhasnans\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'results'"
     ]
    }
   ],
   "source": [
    "print(test_results.head())\n",
    "for d in test_results['results'].head():\n",
    "    print(d)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2451\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "            gene_ids                                          pass/fail\n",
      "0  [ENSG00000000419]  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "1  [ENSG00000000938]  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "2  [ENSG00000001036]  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "3  [ENSG00000001084]  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "4  [ENSG00000001630]  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "2451\n"
     ]
    }
   ],
   "source": [
    "essential = pd.read_csv('C:/Users/Sigve/Genome_Data/results/model_tests/brain_model_essential.csv', index_col=0)\n",
    "\n",
    "essential['pass/fail'] = essential.values.tolist()\n",
    "essential = essential[['pass/fail']].reset_index()\n",
    "print(essential.shape[0])\n",
    "essential['pass/fail'] = essential['pass/fail'].apply(lambda x: x[:-1] + [int(x[-1][0])])\n",
    "\n",
    "#essential = essential[essential['pass/fail'].map(lambda x: any(task == 1 for task in x))]\n",
    "essential['gene_ids'] = essential['Var1'].apply(lambda x: [x])\n",
    "essential = pd.DataFrame(essential[['gene_ids', 'pass/fail']])\n",
    "essential['pass/fail'] = essential['pass/fail'].apply(lambda x: [1 if i==0 else 0 for i in x])\n",
    "essential.reset_index(inplace=True, drop=True)\n",
    "print(essential.head())\n",
    "print(essential.shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            gene_ids   solution  \\\n",
      "0  [ENSG00000000419]  87.693483   \n",
      "1  [ENSG00000000938]  87.693483   \n",
      "2  [ENSG00000001036]  87.693483   \n",
      "3  [ENSG00000001084]  87.693483   \n",
      "4  [ENSG00000001630]   0.000000   \n",
      "\n",
      "                                       tasks_results  \\\n",
      "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
      "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
      "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
      "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
      "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
      "\n",
      "                                              MATLAB  \n",
      "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
      "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
      "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
      "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
      "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n"
     ]
    }
   ],
   "source": [
    "comparison_df = test_results.copy()\n",
    "comparison_df['MATLAB'] = essential['pass/fail']\n",
    "print(comparison_df.head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n"
     ]
    }
   ],
   "source": [
    "#comparison_df['MATLAB'] = comparison_df['MATLAB'].apply(lambda x: x[:-1] + [abs(x[-1]-1)])\n",
    "\n",
    "#print(len(comparison_df['MATLAB'].iloc[0]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of detected errors: 0\n"
     ]
    }
   ],
   "source": [
    "# Data comparison\n",
    "\n",
    "comparison_df['comparison'] = comparison_df[['tasks_results', 'MATLAB']].apply(lambda x: any([False if i == j else True for i, j in zip(x[0], x[1])]), axis=1)\n",
    "error_df = comparison_df[comparison_df['comparison']]\n",
    "\n",
    "print('Number of detected errors: ' + str(error_df.shape[0]))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "# Check which tasks have failed at least once\n",
    "indicies = []\n",
    "for ind, data in comparison_df.iterrows():\n",
    "    i = 0\n",
    "    for j in data.tasks_results:\n",
    "        i += 1\n",
    "        if not bool(j):\n",
    "            indicies.append(i)\n",
    "\n",
    "indicies.sort()\n",
    "print(set(indicies))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2315\n",
      "2163\n"
     ]
    }
   ],
   "source": [
    "# Extract essential on solution/tasks\n",
    "essential_genes = comparison_df[comparison_df['solution'].map(lambda x: x!=0)]\n",
    "print(essential_genes.shape[0])\n",
    "essential_genes = essential_genes[essential_genes['tasks_results'].map(lambda x: not any([True if i==0 else False for i in x]))]\n",
    "print(essential_genes.shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2163\n"
     ]
    }
   ],
   "source": [
    "# Extract (non-)essential on both solution and tasks\n",
    "\n",
    "essential_genes = comparison_df[((comparison_df['solution'] != 0) & (comparison_df['tasks_results'].apply(lambda x: not any([True if i==0 else False for i in x]))))]\n",
    "essential_genes.reset_index(drop=True, inplace=True)\n",
    "print(essential_genes.shape[0])\n",
    "\n",
    "pd.DataFrame(essential_genes['gene_ids'].apply(lambda x: x[0]), columns=['gene_ids']).to_csv(path_or_buf='C:/Users/Sigve/Genome_Data/results/model_tests/model_non_ess_genes_ext.tsv', sep='\\t')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Check if any run with zero as solution passed all tasks\n",
    "essential_genes = comparison_df[comparison_df['solution'].map(lambda x: x==0)]\n",
    "print(essential_genes.shape[0])\n",
    "essential_genes = essential_genes[essential_genes['tasks_results'].map(lambda x: not any([True if i==0 else False for i in x]))]\n",
    "print(essential_genes.shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}